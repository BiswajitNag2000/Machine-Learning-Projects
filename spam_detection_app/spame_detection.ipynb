{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n",
        "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "df.rename(columns={'v1': 'message_type', 'v2': 'message'}, inplace=True)\n",
        "\n",
        "# Preprocessing and feature extraction\n",
        "df['message_type'] = df['message_type'].map({'ham': 0, 'spam': 1})\n",
        "df['num_characters'] = df['message'].apply(len)\n",
        "\n",
        "# Text preprocessing functions\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Removing punctuation and stopwords\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Apply preprocessing to messages\n",
        "df['processed_message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf_vectorizer.fit_transform(df['processed_message']).toarray()\n",
        "y = df['message_type']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Naive Bayes classifier training and evaluation\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsDvyHJv-7xD",
        "outputId": "4ac2caa4-2d3a-4346-c49a-2c3f906687ba"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.9632286995515695\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 41 109]]\n",
            "Precision: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n",
        "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "df.rename(columns={'v1': 'message_type', 'v2': 'message'}, inplace=True)\n",
        "\n",
        "# Preprocessing and feature extraction\n",
        "df['message_type'] = df['message_type'].map({'ham': 0, 'spam': 1})\n",
        "df['num_characters'] = df['message'].apply(len)\n",
        "\n",
        "# Text preprocessing functions\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Apply preprocessing to messages\n",
        "df['processed_message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Define pipeline with TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'tfidf__max_features': [100, 500, 1000, 2000, 3000, 5000],\n",
        "    'tfidf__use_idf': [True, False],\n",
        "    'tfidf__sublinear_tf': [True, False]\n",
        "}\n",
        "\n",
        "# Split the dataset\n",
        "X = df['processed_message']\n",
        "y = df['message_type']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Model Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Model Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KQpGXaSCs-N",
        "outputId": "6d46e81e-8e88-4607-b47e-663dfdecb2a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Best Model Parameters: {'tfidf__max_features': 1000, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': False}\n",
            "Best Model Accuracy: 0.9650224215246637\n",
            "Confusion Matrix:\n",
            " [[962   3]\n",
            " [ 36 114]]\n",
            "Precision: 0.9743589743589743\n"
          ]
        }
      ]
    }
  ]
}