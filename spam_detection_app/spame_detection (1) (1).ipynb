{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n",
        "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "df.rename(columns={'v1': 'message_type', 'v2': 'message'}, inplace=True)\n",
        "\n",
        "# Preprocessing and feature extraction\n",
        "df['message_type'] = df['message_type'].map({'ham': 0, 'spam': 1})\n",
        "df['num_characters'] = df['message'].apply(len)\n",
        "\n",
        "# Text preprocessing functions\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    # Removing punctuation and stopwords\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Apply preprocessing to messages\n",
        "df['processed_message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Feature extraction using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = tfidf_vectorizer.fit_transform(df['processed_message']).toarray()\n",
        "y = df['message_type']\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Naive Bayes classifier training and evaluation\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "print(\"Naive Bayes Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsDvyHJv-7xD",
        "outputId": "4ac2caa4-2d3a-4346-c49a-2c3f906687ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy: 0.9632286995515695\n",
            "Confusion Matrix:\n",
            " [[965   0]\n",
            " [ 41 109]]\n",
            "Precision: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding='latin-1')\n",
        "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
        "df.rename(columns={'v1': 'message_type', 'v2': 'message'}, inplace=True)\n",
        "\n",
        "# Preprocessing and feature extraction\n",
        "df['message_type'] = df['message_type'].map({'ham': 0, 'spam': 1})\n",
        "df['num_characters'] = df['message'].apply(len)\n",
        "\n",
        "# Text preprocessing functions\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens = [word for word in tokens if word.isalpha() and word not in stopwords.words('english')]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
        "    return ' '.join(stemmed_tokens)\n",
        "\n",
        "# Apply preprocessing to messages\n",
        "df['processed_message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Define pipeline with TfidfVectorizer and MultinomialNB\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Define parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'tfidf__max_features': [100, 500, 1000, 2000, 3000, 5000],\n",
        "    'tfidf__use_idf': [True, False],\n",
        "    'tfidf__sublinear_tf': [True, False]\n",
        "}\n",
        "\n",
        "# Split the dataset\n",
        "X = df['processed_message']\n",
        "y = df['message_type']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Model Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Model Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KQpGXaSCs-N",
        "outputId": "6d46e81e-8e88-4607-b47e-663dfdecb2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Best Model Parameters: {'tfidf__max_features': 1000, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': False}\n",
            "Best Model Accuracy: 0.9650224215246637\n",
            "Confusion Matrix:\n",
            " [[962   3]\n",
            " [ 36 114]]\n",
            "Precision: 0.9743589743589743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a website using Streamlit to showcase your spam detection model and its accuracy is a great idea! Streamlit is a Python library that allows you to create interactive web applications with minimal code. Below is a basic example of how you can create a Streamlit web app for your spam detection model:"
      ],
      "metadata": {
        "id": "sZhpZxDWKTKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, make sure you have Streamlit installed. You can install it using the following command"
      ],
      "metadata": {
        "id": "8sopY6KIKaKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n"
      ],
      "metadata": {
        "id": "GJOEKVtDKhN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a Python file (e.g., app.py) with the following code:"
      ],
      "metadata": {
        "id": "cY2vjzEdKlPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the pickled objects\n",
        "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
        "model = pickle.load(open('model.pkl', 'rb'))\n",
        "\n",
        "# Function to preprocess input text\n",
        "def preprocess_text(text):\n",
        "    # Put your preprocessing code here (similar to what you used in training)\n",
        "    return text\n",
        "\n",
        "# Streamlit UI elements\n",
        "st.title('Spam Detection Web App')\n",
        "st.write('Enter a message to predict if it\\'s spam or not:')\n",
        "\n",
        "input_text = st.text_area('Enter your message', '')\n",
        "\n",
        "if st.button('Predict'):\n",
        "    if input_text:\n",
        "        preprocessed_text = preprocess_text(input_text)\n",
        "        transformed_text = vectorizer.transform([preprocessed_text])\n",
        "        prediction = model.predict(transformed_text)[0]\n",
        "\n",
        "        if prediction == 1:\n",
        "            st.error('Spam')\n",
        "        else:\n",
        "            st.success('Not Spam')\n",
        "\n",
        "# Additional section to showcase accuracy\n",
        "st.subheader('Model Accuracy')\n",
        "accuracy = 0.0  # Load and calculate accuracy here\n",
        "st.write(f'Model Accuracy: {accuracy:.2%}')\n"
      ],
      "metadata": {
        "id": "QTwthjZ1KtNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place the vectorizer.pkl and model.pkl files in the same directory as your app.py file.\n",
        "\n",
        "Open a terminal, navigate to the directory containing app.py, and run the following command:"
      ],
      "metadata": {
        "id": "WqBMuAoTKygX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.py\n"
      ],
      "metadata": {
        "id": "FVTWx-AuK6Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will launch a web app in your browser where you can input text and get predictions from your model.\n"
      ],
      "metadata": {
        "id": "pxhIEPTHK9GY"
      }
    }
  ]
}